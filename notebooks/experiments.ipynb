{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy and stanfordnlp comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_spacy = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "# stanfordnlp.download('de')\n",
    "nlp_stanford = stanfordnlp.Pipeline(lang='de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab #Frohnau 21:58 Uhr und erster Zug ab #Hohen_Neuendorf 22:03 Uhr.\"\n",
    "doc2 = \"Unfall\\nAbschnitt: Marzahn (Berlin)\\nGültig ab: 09.02.2016 20:06\\ngesperrt, Unfall\\n\"\n",
    "doc3 = \"■ #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau.  Dort ist wegen #Bauarbeiten nur eine Spur frei.\\n\"\n",
    "doc4 = \"Wegen einer techn. Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw. Halensee <> Westkreuz <> Messe Nord <> Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt. Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.\"\n",
    "doc5 = \"#S3, #S5, #S7, #S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process documents with spaCy and stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_docs = [nlp_spacy(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_docs = [nlp_stanford(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization comparison\n",
    "How to access tokens:\n",
    "\n",
    "#### spaCy\n",
    "`Doc` is a sequence of `Token`s. We can get the token text with `Token.text`.\n",
    "\n",
    "#### stanfordnlp\n",
    "Here we have to access the sentences of a `Doc` to access the tokens with `tokens` property. We can get the token text with `Token.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_spacy_doc_tokens(doc):\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def get_stanford_doc_tokens(doc):\n",
    "    return [token.text for sentence in doc.sentences for token in sentence.tokens]\n",
    "\n",
    "def print_list_differences(list_a, list_b):\n",
    "    d = difflib.Differ()\n",
    "    result = list(d.compare(list_a, list_b))\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_tokens = get_spacy_doc_tokens(spacy_doc)\n",
    "    print(\"spaCy:\", spacy_tokens)\n",
    "    stanford_tokens = get_stanford_doc_tokens(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_tokens)\n",
    "    print(\"\\nDifferences:\")\n",
    "    print_list_differences(spacy_tokens, stanford_tokens)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitting comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_sentences(doc):\n",
    "    return [s.text for s in doc.sents]\n",
    "\n",
    "def get_stanford_doc_sentences(doc):\n",
    "    # introduces whitespaces\n",
    "    # see: https://github.com/stanfordnlp/stanfordnlp/blob/dev/stanfordnlp/models/common/doc.py\n",
    "    # to get original sentence text\n",
    "    return [\" \".join([t.text for t in s.tokens]) for s in stanford_doc.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_sentences = get_spacy_doc_sentences(spacy_doc)\n",
    "    print(\"spaCy:\", len(spacy_sentences), \"\\n\", spacy_sentences)\n",
    "    stanford_sentences = get_stanford_doc_sentences(stanford_doc)\n",
    "    print(\"stanfordnlp:\", len(stanford_sentences), \"\\n\", stanford_sentences)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoS comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_pos(doc):\n",
    "    # fine-grained would be token.tag\n",
    "    return [token.tag_ for token in doc]\n",
    "\n",
    "def get_stanford_doc_pos(doc):\n",
    "    return [word.pos for sentence in doc.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_pos = get_spacy_doc_pos(spacy_doc)\n",
    "    print(spacy_doc.text)\n",
    "    print(\"spaCy:\", spacy_pos)\n",
    "    stanford_pos = get_stanford_doc_pos(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_pos)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_dep(doc):\n",
    "    return [token.dep_ for token in doc]\n",
    "\n",
    "def get_stanford_doc_dep(doc):\n",
    "    return [word.dependency_relation for sentence in doc.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_dep = get_spacy_doc_dep(spacy_doc)\n",
    "    print(spacy_doc.text)\n",
    "    print(\"spaCy:\", spacy_dep)\n",
    "    stanford_dep = get_stanford_doc_dep(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_dep)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
