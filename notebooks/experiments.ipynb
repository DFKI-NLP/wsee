{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy and stanfordnlp comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_spacy = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"de_gsd\" for language \"de\".\n",
      "Would you like to download the models for: de_gsd now? (Y/n)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default download directory: /Users/phuc/stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading models for: de_gsd\n",
      "Download location: /Users/phuc/stanfordnlp_resources/de_gsd_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229M/229M [00:40<00:00, 5.64MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: /Users/phuc/stanfordnlp_resources/de_gsd_models.zip\n",
      "Extracting models file for: de_gsd\n",
      "Cleaning up...Done.\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_tokenizer.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_mwt_expander.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_tagger.pt', 'pretrain_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd.pretrain.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_lemmatizer.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_parser.pt', 'pretrain_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd.pretrain.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "# stanfordnlp.download('de')\n",
    "nlp_stanford = stanfordnlp.Pipeline(lang='de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab #Frohnau 21:58 Uhr und erster Zug ab #Hohen_Neuendorf 22:03 Uhr.\"\n",
    "doc2 = \"Unfall\\nAbschnitt: Marzahn (Berlin)\\nGültig ab: 09.02.2016 20:06\\ngesperrt, Unfall\\n\"\n",
    "doc3 = \"■ #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau.  Dort ist wegen #Bauarbeiten nur eine Spur frei.\\n\"\n",
    "doc4 = \"Wegen einer techn. Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw. Halensee <> Westkreuz <> Messe Nord <> Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt. Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.\"\n",
    "doc5 = \"#S3, #S5, #S7, #S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process documents with spaCy and stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_docs = [nlp_spacy(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_docs = [nlp_stanford(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization comparison\n",
    "How to access tokens:\n",
    "\n",
    "#### spaCy\n",
    "`Doc` is a sequence of `Token`s. We can get the token text with `Token.text`.\n",
    "\n",
    "#### stanfordnlp\n",
    "Here we have to access the sentences of a `Doc` to access the tokens with `tokens` property. We can get the token text with `Token.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_spacy_doc_tokens(doc):\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def get_stanford_doc_tokens(doc):\n",
    "    return [token.text for sentence in doc.sentences for token in sentence.tokens]\n",
    "\n",
    "def print_list_differences(list_a, list_b):\n",
    "    d = difflib.Differ()\n",
    "    result = list(d.compare(list_a, list_b))\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy: ['#', 'S1', 'Nach', 'der', 'Weichenstörung', 'in', 'Hohen', 'Neuendorf', 'verkehren', 'die', 'S-Bahnen', 'wieder', 'durchgehend', ',', 'erster', 'Zug', 'ab', '#', 'Frohnau', '21:58', 'Uhr', 'und', 'erster', 'Zug', 'ab', '#', 'Hohen_Neuendorf', '22:03', 'Uhr', '.']\n",
      "stanfordnlp: ['#S1', 'Nach', 'der', 'Weichenstörung', 'in', 'Hohen', 'Neuendorf', 'verkehren', 'die', 'S-', 'Bahnen', 'wieder', 'durchgehend', ',', 'erster', 'Zug', 'ab', '#', 'Frohnau', '21:58', 'Uhr', 'und', 'erster', 'Zug', 'ab', '#', 'Hohen_Neuendorf', '22:03', 'Uhr', '.']\n",
      "\n",
      "Differences:\n",
      "['- #',\n",
      " '- S1',\n",
      " '+ #S1',\n",
      " '? +\\n',\n",
      " '  Nach',\n",
      " '  der',\n",
      " '  Weichenstörung',\n",
      " '  in',\n",
      " '  Hohen',\n",
      " '  Neuendorf',\n",
      " '  verkehren',\n",
      " '  die',\n",
      " '+ S-',\n",
      " '- S-Bahnen',\n",
      " '? --\\n',\n",
      " '+ Bahnen',\n",
      " '  wieder',\n",
      " '  durchgehend',\n",
      " '  ,',\n",
      " '  erster',\n",
      " '  Zug',\n",
      " '  ab',\n",
      " '  #',\n",
      " '  Frohnau',\n",
      " '  21:58',\n",
      " '  Uhr',\n",
      " '  und',\n",
      " '  erster',\n",
      " '  Zug',\n",
      " '  ab',\n",
      " '  #',\n",
      " '  Hohen_Neuendorf',\n",
      " '  22:03',\n",
      " '  Uhr',\n",
      " '  .']\n",
      "\n",
      "\n",
      "spaCy: ['Unfall', '\\n', 'Abschnitt', ':', 'Marzahn', '(', 'Berlin', ')', '\\n', 'Gültig', 'ab', ':', '09.02.2016', '20:06', '\\n', 'gesperrt', ',', 'Unfall', '\\n']\n",
      "stanfordnlp: ['Unfall', 'Abschnitt', ':', 'Marzahn', '(', 'Berlin', ')', 'Gültig', 'ab', ':', '09.02.2016', '20:06', 'gesperrt', ',', 'Unfall']\n",
      "\n",
      "Differences:\n",
      "['  Unfall',\n",
      " '- \\n',\n",
      " '  Abschnitt',\n",
      " '  :',\n",
      " '  Marzahn',\n",
      " '  (',\n",
      " '  Berlin',\n",
      " '  )',\n",
      " '- \\n',\n",
      " '  Gültig',\n",
      " '  ab',\n",
      " '  :',\n",
      " '  09.02.2016',\n",
      " '  20:06',\n",
      " '- \\n',\n",
      " '  gesperrt',\n",
      " '  ,',\n",
      " '  Unfall',\n",
      " '- \\n']\n",
      "\n",
      "\n",
      "spaCy: ['■', '#', 'A1', '#', 'Bremen', 'Richtung', '#', 'Hamburg', 'zwischen', 'Horster', 'Dreieck', 'und', '#', 'Stillhorn', '9', 'km', '#', 'Stau', '.', ' ', 'Dort', 'ist', 'wegen', '#', 'Bauarbeiten', 'nur', 'eine', 'Spur', 'frei', '.', '\\n']\n",
      "stanfordnlp: ['■', '#', 'A1', '#', 'Bremen', 'Richtung', '#', 'Hamburg', 'zwischen', 'Horster', 'Dreieck', 'und', '#', 'Stillhorn', '9', 'km', '#', 'Stau', '.', 'Dort', 'ist', 'wegen', '#', 'Bauarbeiten', 'nur', 'eine', 'Spur', 'frei', '.']\n",
      "\n",
      "Differences:\n",
      "['  ■',\n",
      " '  #',\n",
      " '  A1',\n",
      " '  #',\n",
      " '  Bremen',\n",
      " '  Richtung',\n",
      " '  #',\n",
      " '  Hamburg',\n",
      " '  zwischen',\n",
      " '  Horster',\n",
      " '  Dreieck',\n",
      " '  und',\n",
      " '  #',\n",
      " '  Stillhorn',\n",
      " '  9',\n",
      " '  km',\n",
      " '  #',\n",
      " '  Stau',\n",
      " '  .',\n",
      " '-  ',\n",
      " '  Dort',\n",
      " '  ist',\n",
      " '  wegen',\n",
      " '  #',\n",
      " '  Bauarbeiten',\n",
      " '  nur',\n",
      " '  eine',\n",
      " '  Spur',\n",
      " '  frei',\n",
      " '  .',\n",
      " '- \\n']\n",
      "\n",
      "\n",
      "spaCy: ['Wegen', 'einer', 'techn', '.', 'Störung', 'an', 'der', 'Strecke', 'besteht', 'für', 'die', 'Linien', 'S41', ',', 'S42', 'u.', 'S46', 'zw', '.', 'Halensee', '<', '>', 'Westkreuz', '<', '>', 'Messe', 'Nord', '<', '>', 'Westend', 'S-Bahn-Pendelverkehr', 'im', '20-Minuten-Takt', '.', 'Die', 'Linien', 'S41', 'u.', 'S42', 'fahren', 'nur', 'im', '10-Minuten-Takt', ',', 'die', 'Linie', 'S46', 'fährt', 'nur', 'Königs', 'Wusterhausen', '<', '>', 'Tempelhof', '.']\n",
      "stanfordnlp: ['Wegen', 'einer', 'techn', '.', 'Störung', 'an', 'der', 'Strecke', 'besteht', 'für', 'die', 'Linien', 'S41', ',', 'S42', 'u', '.', 'S46', 'zw', '.', 'Halensee', '<>', 'Westkreuz', '<>', 'Messe', 'Nord', '<>', 'Westend', 'S', '-', 'Bahn', '-', 'Pendelverkehr', 'im', '20', '-', 'Minuten', '-', 'Takt', '.', 'Die', 'Linien', 'S41', 'u', '.', 'S42', 'fahren', 'nur', 'im', '10', '-', 'Minuten', '-', 'Takt', ',', 'die', 'Linie', 'S46', 'fährt', 'nur', 'Königs', 'Wusterhausen', '<>', 'Tempelhof', '.']\n",
      "\n",
      "Differences:\n",
      "['  Wegen',\n",
      " '  einer',\n",
      " '  techn',\n",
      " '  .',\n",
      " '  Störung',\n",
      " '  an',\n",
      " '  der',\n",
      " '  Strecke',\n",
      " '  besteht',\n",
      " '  für',\n",
      " '  die',\n",
      " '  Linien',\n",
      " '  S41',\n",
      " '  ,',\n",
      " '  S42',\n",
      " '- u.',\n",
      " '+ u',\n",
      " '+ .',\n",
      " '  S46',\n",
      " '  zw',\n",
      " '  .',\n",
      " '  Halensee',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Westkreuz',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Messe',\n",
      " '  Nord',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Westend',\n",
      " '+ S',\n",
      " '+ -',\n",
      " '+ Bahn',\n",
      " '+ -',\n",
      " '- S-Bahn-Pendelverkehr',\n",
      " '? -------\\n',\n",
      " '+ Pendelverkehr',\n",
      " '  im',\n",
      " '- 20-Minuten-Takt',\n",
      " '+ 20',\n",
      " '+ -',\n",
      " '+ Minuten',\n",
      " '+ -',\n",
      " '+ Takt',\n",
      " '  .',\n",
      " '  Die',\n",
      " '  Linien',\n",
      " '  S41',\n",
      " '- u.',\n",
      " '+ u',\n",
      " '+ .',\n",
      " '  S42',\n",
      " '  fahren',\n",
      " '  nur',\n",
      " '  im',\n",
      " '- 10-Minuten-Takt',\n",
      " '+ 10',\n",
      " '+ -',\n",
      " '+ Minuten',\n",
      " '+ -',\n",
      " '+ Takt',\n",
      " '  ,',\n",
      " '  die',\n",
      " '  Linie',\n",
      " '  S46',\n",
      " '  fährt',\n",
      " '  nur',\n",
      " '  Königs',\n",
      " '  Wusterhausen',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Tempelhof',\n",
      " '  .']\n",
      "\n",
      "\n",
      "spaCy: ['#', 'S3', ',', '#', 'S5', ',', '#', 'S7', ',', '#', 'S9', ':', 'Nach', 'einer', 'ärztliche', 'Versorgung', 'eines', 'Fahrgastes', 'im', 'Zug', 'in', 'Bellevue', 'kommt', 'es', 'noch', 'zu', 'Verspätungen', 'und', 'vereinzelten', 'Ausfällen', '.']\n",
      "stanfordnlp: ['#S3', ',', '#', 'S5', ',', '#', 'S7', ',', '#', 'S9', ':', 'Nach', 'einer', 'ärztliche', 'Versorgung', 'eines', 'Fahrgastes', 'im', 'Zug', 'in', 'Bellevue', 'kommt', 'es', 'noch', 'zu', 'Verspätungen', 'und', 'vereinzelten', 'Ausfällen', '.']\n",
      "\n",
      "Differences:\n",
      "['- #',\n",
      " '- S3',\n",
      " '+ #S3',\n",
      " '? +\\n',\n",
      " '  ,',\n",
      " '  #',\n",
      " '  S5',\n",
      " '  ,',\n",
      " '  #',\n",
      " '  S7',\n",
      " '  ,',\n",
      " '  #',\n",
      " '  S9',\n",
      " '  :',\n",
      " '  Nach',\n",
      " '  einer',\n",
      " '  ärztliche',\n",
      " '  Versorgung',\n",
      " '  eines',\n",
      " '  Fahrgastes',\n",
      " '  im',\n",
      " '  Zug',\n",
      " '  in',\n",
      " '  Bellevue',\n",
      " '  kommt',\n",
      " '  es',\n",
      " '  noch',\n",
      " '  zu',\n",
      " '  Verspätungen',\n",
      " '  und',\n",
      " '  vereinzelten',\n",
      " '  Ausfällen',\n",
      " '  .']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_tokens = get_spacy_doc_tokens(spacy_doc)\n",
    "    print(\"spaCy:\", spacy_tokens)\n",
    "    stanford_tokens = get_stanford_doc_tokens(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_tokens)\n",
    "    print(\"\\nDifferences:\")\n",
    "    print_list_differences(spacy_tokens, stanford_tokens)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitting comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_sentences(doc):\n",
    "    return [s.text for s in doc.sents]\n",
    "\n",
    "def get_stanford_doc_sentences(doc):\n",
    "    # introduces whitespaces\n",
    "    # see: https://github.com/stanfordnlp/stanfordnlp/blob/dev/stanfordnlp/models/common/doc.py\n",
    "    # to get original sentence text\n",
    "    return [\" \".join([t.text for t in s.tokens]) for s in stanford_doc.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy: 7 \n",
      " ['#S1', 'Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab', '#', 'Frohnau', '21:58 Uhr und erster Zug ab', '#Hohen_Neuendorf', '22:03 Uhr.']\n",
      "stanfordnlp: 1 \n",
      " ['#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S- Bahnen wieder durchgehend , erster Zug ab # Frohnau 21:58 Uhr und erster Zug ab # Hohen_Neuendorf 22:03 Uhr .']\n",
      "\n",
      "\n",
      "spaCy: 5 \n",
      " ['Unfall\\nAbschnitt: Marzahn (Berlin)\\n', 'Gültig ab', ':', '09.02.2016', '20:06\\ngesperrt, Unfall\\n']\n",
      "stanfordnlp: 1 \n",
      " ['Unfall Abschnitt : Marzahn ( Berlin ) Gültig ab : 09.02.2016 20:06 gesperrt , Unfall']\n",
      "\n",
      "\n",
      "spaCy: 6 \n",
      " ['■', '#', 'A1 #Bremen', 'Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn', '9 km #Stau.  ', 'Dort ist wegen #Bauarbeiten nur eine Spur frei.\\n']\n",
      "stanfordnlp: 2 \n",
      " ['■ # A1 # Bremen Richtung # Hamburg zwischen Horster Dreieck und # Stillhorn 9 km # Stau .', 'Dort ist wegen # Bauarbeiten nur eine Spur frei .']\n",
      "\n",
      "\n",
      "spaCy: 7 \n",
      " ['Wegen einer techn.', 'Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw.', 'Halensee <>', 'Westkreuz <>', 'Messe Nord <>', 'Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt.', 'Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.']\n",
      "stanfordnlp: 5 \n",
      " ['Wegen einer techn .', 'Störung an der Strecke besteht für die Linien S41 , S42 u .', 'S46 zw . Halensee <> Westkreuz <> Messe Nord <> Westend S - Bahn - Pendelverkehr im 20 - Minuten - Takt .', 'Die Linien S41 u .', 'S42 fahren nur im 10 - Minuten - Takt , die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof .']\n",
      "\n",
      "\n",
      "spaCy: 2 \n",
      " ['#S3, #S5, #S7,', '#S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.']\n",
      "stanfordnlp: 1 \n",
      " ['#S3 , # S5 , # S7 , # S9 : Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen .']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_sentences = get_spacy_doc_sentences(spacy_doc)\n",
    "    print(\"spaCy:\", len(spacy_sentences), \"\\n\", spacy_sentences)\n",
    "    stanford_sentences = get_stanford_doc_sentences(stanford_doc)\n",
    "    print(\"stanfordnlp:\", len(stanford_sentences), \"\\n\", stanford_sentences)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoS comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_pos(doc):\n",
    "    # fine-grained would be token.tag\n",
    "    return [token.tag_ for token in doc]\n",
    "\n",
    "def get_stanford_doc_pos(doc):\n",
    "    return [word.pos for sentence in doc.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab #Frohnau 21:58 Uhr und erster Zug ab #Hohen_Neuendorf 22:03 Uhr.\n",
      "spaCy: ['NE', 'NE', 'APPR', 'ART', 'NN', 'APPR', 'ADJA', 'NE', 'VVFIN', 'ART', 'NN', 'ADV', 'ADJD', '$,', 'ADJA', 'NN', 'PTKVZ', 'NE', 'NE', 'NE', 'NN', 'KON', 'ADJA', 'NN', 'PTKVZ', 'NE', 'NE', 'CARD', 'NN', '$.']\n",
      "stanfordnlp: ['CARD', 'APPR', 'ART', 'NN', 'APPR', 'ADJA', 'NE', 'VVFIN', 'ART', 'NN', 'NN', 'ADV', 'ADJD', '$,', 'ADJA', 'NN', 'APPR', '$(', 'NE', 'CARD', 'NN', 'KON', 'ADJA', 'NN', 'APPR', '$(', 'NN', 'CARD', 'NN', '$.']\n",
      "\n",
      "\n",
      "Unfall\n",
      "Abschnitt: Marzahn (Berlin)\n",
      "Gültig ab: 09.02.2016 20:06\n",
      "gesperrt, Unfall\n",
      "\n",
      "spaCy: ['NN', '_SP', 'NE', '$.', 'NE', '$(', 'NE', '$(', '_SP', 'ADJD', 'PTKVZ', '$.', 'NN', 'NE', '_SP', 'VVPP', '$,', 'NN', '_SP']\n",
      "stanfordnlp: ['NN', 'NN', '$.', 'NE', '$(', 'NE', '$(', 'NE', 'PTKVZ', '$.', 'CARD', 'CARD', 'VVPP', '$,', 'NN']\n",
      "\n",
      "\n",
      "■ #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau.  Dort ist wegen #Bauarbeiten nur eine Spur frei.\n",
      "\n",
      "spaCy: ['NE', 'NE', 'NE', 'NE', 'NE', 'NN', 'NE', 'NE', 'APPR', 'NE', 'NE', 'KON', 'NE', 'NE', 'CARD', 'XY', 'NE', 'NE', '$.', '_SP', 'ADV', 'VAFIN', 'APPR', 'NE', 'NN', 'ADV', 'ART', 'NN', 'ADJD', '$.', '_SP']\n",
      "stanfordnlp: ['$(', 'NE', 'CARD', 'NE', 'NE', 'NN', 'NE', 'NE', 'APPR', 'NE', 'NE', 'KON', 'NE', 'NE', 'CARD', 'NN', 'NE', 'NN', '$.', 'ADV', 'VAFIN', 'APPR', 'ADJA', 'NN', 'ADV', 'ART', 'NN', 'ADJD', '$.']\n",
      "\n",
      "\n",
      "Wegen einer techn. Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw. Halensee <> Westkreuz <> Messe Nord <> Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt. Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.\n",
      "spaCy: ['APPR', 'ART', 'ADJA', '$.', 'NN', 'APPR', 'ART', 'NN', 'VVFIN', 'APPR', 'ART', 'NN', 'NE', '$,', 'NE', 'APPR', 'NN', 'XY', '$.', 'NE', 'NE', 'XY', 'NN', 'NE', 'XY', 'NN', 'NE', 'NE', 'XY', 'NE', 'NN', 'APPRART', 'NN', '$.', 'ART', 'NN', 'NE', 'APPR', 'NN', 'VVFIN', 'ADV', 'APPRART', 'NN', '$,', 'ART', 'NN', 'NN', 'VVFIN', 'ADV', 'NE', 'NE', 'NE', 'XY', 'NE', '$.']\n",
      "stanfordnlp: ['APPR', 'ART', 'NN', '$.', 'NN', 'APPR', 'ART', 'NN', 'VVFIN', 'APPR', 'ART', 'NN', 'NE', '$,', 'NE', 'XY', '$.', 'NE', 'NE', '$.', 'NE', 'APPR', 'ART', 'NN', '$(', 'NN', 'NE', '$(', 'NE', 'NN', '$(', 'NN', '$(', 'NN', 'APPR', 'ART', 'NN', '$(', 'NN', '$(', 'NN', '$.', 'ART', 'NN', 'NE', 'XY', '$.', 'NE', 'VVFIN', 'ADV', 'APPR', 'ART', 'NN', '$(', 'NN', '$(', 'NN', '$,', 'ART', 'NN', 'NE', 'VVFIN', 'ADV', 'NN', 'NE', '$(', 'NE', '$.']\n",
      "\n",
      "\n",
      "#S3, #S5, #S7, #S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.\n",
      "spaCy: ['NE', 'NE', '$,', 'NE', 'NE', '$,', 'NE', 'NE', '$,', 'NE', 'NE', '$.', 'APPR', 'ART', 'ADJA', 'NN', 'ART', 'NN', 'APPRART', 'NN', 'APPR', 'NE', 'VVFIN', 'PPER', 'ADV', 'APPR', 'NN', 'KON', 'ADJA', 'NN', '$.']\n",
      "stanfordnlp: ['CARD', '$,', 'NE', 'NE', '$,', 'NE', 'NE', '$,', 'NE', 'NE', '$.', 'APPR', 'ART', 'ADJA', 'NN', 'ART', 'NN', 'APPR', 'ART', 'NN', 'APPR', 'NE', 'VVFIN', 'PPER', 'ADV', 'APPR', 'NN', 'KON', 'ADJA', 'NN', '$.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_pos = get_spacy_doc_pos(spacy_doc)\n",
    "    print(spacy_doc.text)\n",
    "    print(\"spaCy:\", spacy_pos)\n",
    "    stanford_pos = get_stanford_doc_pos(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_pos)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_dep(doc):\n",
    "    return [token.dep_ for token in doc]\n",
    "\n",
    "def get_stanford_doc_dep(doc):\n",
    "    return [word.dependency_relation for sentence in doc.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab #Frohnau 21:58 Uhr und erster Zug ab #Hohen_Neuendorf 22:03 Uhr.\n",
      "spaCy: ['pnc', 'ROOT', 'mo', 'nk', 'nk', 'mnr', 'nk', 'nk', 'ROOT', 'nk', 'sb', 'mo', 'mo', 'punct', 'nk', 'oa', 'svp', 'ROOT', 'ROOT', 'nk', 'ROOT', 'cd', 'nk', 'cj', 'svp', 'pnc', 'ROOT', 'nk', 'ROOT', 'punct']\n",
      "stanfordnlp: ['obl', 'case', 'det', 'obl', 'case', 'amod', 'nmod', 'root', 'det', 'nsubj', 'obj', 'advmod', 'advmod', 'punct', 'amod', 'conj', 'case', 'punct', 'nmod', 'nummod', 'flat', 'cc', 'amod', 'conj', 'case', 'punct', 'nmod', 'nummod', 'nmod', 'punct']\n",
      "\n",
      "\n",
      "Unfall\n",
      "Abschnitt: Marzahn (Berlin)\n",
      "Gültig ab: 09.02.2016 20:06\n",
      "gesperrt, Unfall\n",
      "\n",
      "spaCy: ['ROOT', '', 'nk', 'punct', 'par', 'punct', 'par', 'punct', '', 'ROOT', 'svp', 'ROOT', 'ROOT', 'sb', '', 'ROOT', 'punct', 'oa', '']\n",
      "stanfordnlp: ['dep', 'dep', 'punct', 'appos', 'punct', 'appos', 'punct', 'appos', 'compound:prt', 'punct', 'nummod', 'nsubj:pass', 'root', 'punct', 'dep']\n",
      "\n",
      "\n",
      "■ #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau.  Dort ist wegen #Bauarbeiten nur eine Spur frei.\n",
      "\n",
      "spaCy: ['ROOT', 'ROOT', 'pnc', 'pnc', 'ROOT', 'ROOT', 'pnc', 'nk', 'mnr', 'nk', 'nk', 'cd', 'pnc', 'cj', 'nmc', 'pnc', 'pnc', 'ROOT', 'punct', '', 'mo', 'ROOT', 'mo', 'pnc', 'nk', 'mo', 'nk', 'sb', 'pd', 'punct', '']\n",
      "stanfordnlp: ['punct', 'root', 'appos', 'punct', 'flat', 'appos', 'appos', 'appos', 'case', 'nmod', 'flat', 'cc', 'conj', 'flat', 'nummod', 'nmod', 'punct', 'appos', 'punct', 'advmod', 'cop', 'case', 'amod', 'nmod', 'advmod', 'det', 'nsubj', 'root', 'punct']\n",
      "\n",
      "\n",
      "Wegen einer techn. Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw. Halensee <> Westkreuz <> Messe Nord <> Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt. Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.\n",
      "spaCy: ['ROOT', 'nk', 'nk', 'punct', 'sb', 'mnr', 'nk', 'nk', 'ROOT', 'mo', 'nk', 'nk', 'subtok', 'punct', 'ac', 'mnr', 'nk', 'nk', 'punct', 'pnc', 'ROOT', 'punct', 'pnc', 'subtok', 'ROOT', 'ROOT', 'pnc', 'nk', 'punct', 'pnc', 'ROOT', 'mnr', 'nk', 'punct', 'nk', 'sb', 'cj', 'mo', 'nk', 'ROOT', 'mo', 'mo', 'nk', 'punct', 'nk', 'sb', 'nk', 'cj', 'mo', 'pnc', 'pnc', 'mo', 'punct', 'oa', 'punct']\n",
      "stanfordnlp: ['case', 'det', 'root', 'punct', 'nsubj', 'case', 'det', 'nmod', 'root', 'case', 'det', 'obl', 'appos', 'punct', 'conj', 'appos', 'punct', 'root', 'appos', 'punct', 'flat', 'case', 'det', 'nmod', 'punct', 'flat', 'appos', 'punct', 'conj', 'compound', 'punct', 'flat', 'punct', 'flat', 'case', 'det', 'compound', 'punct', 'compound', 'punct', 'nmod', 'punct', 'det', 'root', 'appos', 'appos', 'punct', 'nsubj', 'root', 'advmod', 'case', 'det', 'nummod', 'punct', 'compound', 'punct', 'obl', 'punct', 'det', 'nsubj', 'appos', 'conj', 'advmod', 'obj', 'appos', 'case', 'flat', 'punct']\n",
      "\n",
      "\n",
      "#S3, #S5, #S7, #S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.\n",
      "spaCy: ['pnc', 'ROOT', 'punct', 'pnc', 'app', 'punct', 'pnc', 'cj', 'punct', 'pnc', 'cj', 'punct', 'mo', 'nk', 'nk', 'nk', 'nk', 'ag', 'mnr', 'nk', 'mnr', 'nk', 'ROOT', 'ep', 'mo', 'mo', 'nk', 'cd', 'nk', 'cj', 'punct']\n",
      "stanfordnlp: ['nsubj', 'punct', 'amod', 'conj', 'punct', 'amod', 'conj', 'punct', 'cc', 'conj', 'punct', 'case', 'det', 'amod', 'obl', 'det', 'nmod', 'case', 'det', 'nmod', 'case', 'nmod', 'root', 'nsubj', 'advmod', 'case', 'obl', 'cc', 'amod', 'conj', 'punct']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_dep = get_spacy_doc_dep(spacy_doc)\n",
    "    print(spacy_doc.text)\n",
    "    print(\"spaCy:\", spacy_dep)\n",
    "    stanford_dep = get_stanford_doc_dep(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_dep)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
