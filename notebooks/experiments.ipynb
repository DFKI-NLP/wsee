{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy, stanfordnlp, SoMaJo comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_spacy = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_tokenizer.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_mwt_expander.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_tagger.pt', 'pretrain_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd.pretrain.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_lemmatizer.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd_parser.pt', 'pretrain_path': '/Users/phuc/stanfordnlp_resources/de_gsd_models/de_gsd.pretrain.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "# stanfordnlp.download('de')\n",
    "nlp_stanford = stanfordnlp.Pipeline(lang='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from somajo import SoMaJo\n",
    "tokenizer = SoMaJo(\"de_CMC\", split_camel_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab #Frohnau 21:58 Uhr und erster Zug ab #Hohen_Neuendorf 22:03 Uhr.\"\n",
    "doc2 = \"Unfall\\nAbschnitt: Marzahn (Berlin)\\nGültig ab: 09.02.2016 20:06\\ngesperrt, Unfall\\n\"\n",
    "doc3 = \"■ #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau.  Dort ist wegen #Bauarbeiten nur eine Spur frei.\\n\"\n",
    "doc4 = \"Wegen einer techn. Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw. Halensee <> Westkreuz <> Messe Nord <> Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt. Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.\"\n",
    "doc5 = \"#S3, #S5, #S7, #S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process documents with spaCy, stanfordnlp, somajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_docs = [nlp_spacy(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_docs = [nlp_stanford(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "somajo_docs = [list(tokenizer.tokenize_text([doc])) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization comparison\n",
    "How to access tokens:\n",
    "\n",
    "#### spaCy\n",
    "`Doc` is a sequence of `Token`s. We can get the token text with `Token.text`.\n",
    "\n",
    "#### stanfordnlp\n",
    "Here we have to access the sentences of a `Doc` to access the tokens with `tokens` property. We can get the token text with `Token.text`.\n",
    "\n",
    "### somajo\n",
    "Similar to stanfordnlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_spacy_doc_tokens(doc):\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def get_stanford_doc_tokens(doc):\n",
    "    return [token.text for sentence in doc.sentences for token in sentence.tokens]\n",
    "\n",
    "def get_somajo_doc_tokens(doc):\n",
    "    return [token.text for sentence in doc for token in sentence]\n",
    "\n",
    "def print_list_differences(list_a, list_b):\n",
    "    d = difflib.Differ()\n",
    "    result = list(d.compare(list_a, list_b))\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy: ['#', 'S1', 'Nach', 'der', 'Weichenstörung', 'in', 'Hohen', 'Neuendorf', 'verkehren', 'die', 'S-Bahnen', 'wieder', 'durchgehend', ',', 'erster', 'Zug', 'ab', '#', 'Frohnau', '21:58', 'Uhr', 'und', 'erster', 'Zug', 'ab', '#', 'Hohen_Neuendorf', '22:03', 'Uhr', '.']\n",
      "stanfordnlp: ['#S1', 'Nach', 'der', 'Weichenstörung', 'in', 'Hohen', 'Neuendorf', 'verkehren', 'die', 'S-', 'Bahnen', 'wieder', 'durchgehend', ',', 'erster', 'Zug', 'ab', '#', 'Frohnau', '21:58', 'Uhr', 'und', 'erster', 'Zug', 'ab', '#', 'Hohen_Neuendorf', '22:03', 'Uhr', '.']\n",
      "somajo: ['#S1', 'Nach', 'der', 'Weichenstörung', 'in', 'Hohen', 'Neuendorf', 'verkehren', 'die', 'S-Bahnen', 'wieder', 'durchgehend', ',', 'erster', 'Zug', 'ab', '#Frohnau', '21:58', 'Uhr', 'und', 'erster', 'Zug', 'ab', '#Hohen_Neuendorf', '22:03', 'Uhr', '.']\n",
      "\n",
      "Differences:\n",
      "['- #',\n",
      " '- S1',\n",
      " '+ #S1',\n",
      " '? +\\n',\n",
      " '  Nach',\n",
      " '  der',\n",
      " '  Weichenstörung',\n",
      " '  in',\n",
      " '  Hohen',\n",
      " '  Neuendorf',\n",
      " '  verkehren',\n",
      " '  die',\n",
      " '+ S-',\n",
      " '- S-Bahnen',\n",
      " '? --\\n',\n",
      " '+ Bahnen',\n",
      " '  wieder',\n",
      " '  durchgehend',\n",
      " '  ,',\n",
      " '  erster',\n",
      " '  Zug',\n",
      " '  ab',\n",
      " '  #',\n",
      " '  Frohnau',\n",
      " '  21:58',\n",
      " '  Uhr',\n",
      " '  und',\n",
      " '  erster',\n",
      " '  Zug',\n",
      " '  ab',\n",
      " '  #',\n",
      " '  Hohen_Neuendorf',\n",
      " '  22:03',\n",
      " '  Uhr',\n",
      " '  .']\n",
      "\n",
      "\n",
      "spaCy: ['Unfall', '\\n', 'Abschnitt', ':', 'Marzahn', '(', 'Berlin', ')', '\\n', 'Gültig', 'ab', ':', '09.02.2016', '20:06', '\\n', 'gesperrt', ',', 'Unfall', '\\n']\n",
      "stanfordnlp: ['Unfall', 'Abschnitt', ':', 'Marzahn', '(', 'Berlin', ')', 'Gültig', 'ab', ':', '09.02.2016', '20:06', 'gesperrt', ',', 'Unfall']\n",
      "somajo: ['Unfall', 'Abschnitt', ':', 'Marzahn', '(', 'Berlin', ')', 'Gültig', 'ab', ':', '09.', '02.', '2016', '20:06', 'gesperrt', ',', 'Unfall']\n",
      "\n",
      "Differences:\n",
      "['  Unfall',\n",
      " '- \\n',\n",
      " '  Abschnitt',\n",
      " '  :',\n",
      " '  Marzahn',\n",
      " '  (',\n",
      " '  Berlin',\n",
      " '  )',\n",
      " '- \\n',\n",
      " '  Gültig',\n",
      " '  ab',\n",
      " '  :',\n",
      " '  09.02.2016',\n",
      " '  20:06',\n",
      " '- \\n',\n",
      " '  gesperrt',\n",
      " '  ,',\n",
      " '  Unfall',\n",
      " '- \\n']\n",
      "\n",
      "\n",
      "spaCy: ['■', '#', 'A1', '#', 'Bremen', 'Richtung', '#', 'Hamburg', 'zwischen', 'Horster', 'Dreieck', 'und', '#', 'Stillhorn', '9', 'km', '#', 'Stau', '.', ' ', 'Dort', 'ist', 'wegen', '#', 'Bauarbeiten', 'nur', 'eine', 'Spur', 'frei', '.', '\\n']\n",
      "stanfordnlp: ['■', '#', 'A1', '#', 'Bremen', 'Richtung', '#', 'Hamburg', 'zwischen', 'Horster', 'Dreieck', 'und', '#', 'Stillhorn', '9', 'km', '#', 'Stau', '.', 'Dort', 'ist', 'wegen', '#', 'Bauarbeiten', 'nur', 'eine', 'Spur', 'frei', '.']\n",
      "somajo: ['■', '#A1', '#Bremen', 'Richtung', '#Hamburg', 'zwischen', 'Horster', 'Dreieck', 'und', '#Stillhorn', '9', 'km', '#Stau', '.', 'Dort', 'ist', 'wegen', '#Bauarbeiten', 'nur', 'eine', 'Spur', 'frei', '.']\n",
      "\n",
      "Differences:\n",
      "['  ■',\n",
      " '  #',\n",
      " '  A1',\n",
      " '  #',\n",
      " '  Bremen',\n",
      " '  Richtung',\n",
      " '  #',\n",
      " '  Hamburg',\n",
      " '  zwischen',\n",
      " '  Horster',\n",
      " '  Dreieck',\n",
      " '  und',\n",
      " '  #',\n",
      " '  Stillhorn',\n",
      " '  9',\n",
      " '  km',\n",
      " '  #',\n",
      " '  Stau',\n",
      " '  .',\n",
      " '-  ',\n",
      " '  Dort',\n",
      " '  ist',\n",
      " '  wegen',\n",
      " '  #',\n",
      " '  Bauarbeiten',\n",
      " '  nur',\n",
      " '  eine',\n",
      " '  Spur',\n",
      " '  frei',\n",
      " '  .',\n",
      " '- \\n']\n",
      "\n",
      "\n",
      "spaCy: ['Wegen', 'einer', 'techn', '.', 'Störung', 'an', 'der', 'Strecke', 'besteht', 'für', 'die', 'Linien', 'S41', ',', 'S42', 'u.', 'S46', 'zw', '.', 'Halensee', '<', '>', 'Westkreuz', '<', '>', 'Messe', 'Nord', '<', '>', 'Westend', 'S-Bahn-Pendelverkehr', 'im', '20-Minuten-Takt', '.', 'Die', 'Linien', 'S41', 'u.', 'S42', 'fahren', 'nur', 'im', '10-Minuten-Takt', ',', 'die', 'Linie', 'S46', 'fährt', 'nur', 'Königs', 'Wusterhausen', '<', '>', 'Tempelhof', '.']\n",
      "stanfordnlp: ['Wegen', 'einer', 'techn', '.', 'Störung', 'an', 'der', 'Strecke', 'besteht', 'für', 'die', 'Linien', 'S41', ',', 'S42', 'u', '.', 'S46', 'zw', '.', 'Halensee', '<>', 'Westkreuz', '<>', 'Messe', 'Nord', '<>', 'Westend', 'S', '-', 'Bahn', '-', 'Pendelverkehr', 'im', '20', '-', 'Minuten', '-', 'Takt', '.', 'Die', 'Linien', 'S41', 'u', '.', 'S42', 'fahren', 'nur', 'im', '10', '-', 'Minuten', '-', 'Takt', ',', 'die', 'Linie', 'S46', 'fährt', 'nur', 'Königs', 'Wusterhausen', '<>', 'Tempelhof', '.']\n",
      "somajo: ['Wegen', 'einer', 'techn.', 'Störung', 'an', 'der', 'Strecke', 'besteht', 'für', 'die', 'Linien', 'S41', ',', 'S42', 'u.', 'S46', 'zw.', 'Halensee', '<', '>', 'Westkreuz', '<', '>', 'Messe', 'Nord', '<', '>', 'Westend', 'S-Bahn-Pendelverkehr', 'im', '20-Minuten-Takt', '.', 'Die', 'Linien', 'S41', 'u.', 'S42', 'fahren', 'nur', 'im', '10-Minuten-Takt', ',', 'die', 'Linie', 'S46', 'fährt', 'nur', 'Königs', 'Wusterhausen', '<', '>', 'Tempelhof', '.']\n",
      "\n",
      "Differences:\n",
      "['  Wegen',\n",
      " '  einer',\n",
      " '  techn',\n",
      " '  .',\n",
      " '  Störung',\n",
      " '  an',\n",
      " '  der',\n",
      " '  Strecke',\n",
      " '  besteht',\n",
      " '  für',\n",
      " '  die',\n",
      " '  Linien',\n",
      " '  S41',\n",
      " '  ,',\n",
      " '  S42',\n",
      " '- u.',\n",
      " '+ u',\n",
      " '+ .',\n",
      " '  S46',\n",
      " '  zw',\n",
      " '  .',\n",
      " '  Halensee',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Westkreuz',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Messe',\n",
      " '  Nord',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Westend',\n",
      " '+ S',\n",
      " '+ -',\n",
      " '+ Bahn',\n",
      " '+ -',\n",
      " '- S-Bahn-Pendelverkehr',\n",
      " '? -------\\n',\n",
      " '+ Pendelverkehr',\n",
      " '  im',\n",
      " '- 20-Minuten-Takt',\n",
      " '+ 20',\n",
      " '+ -',\n",
      " '+ Minuten',\n",
      " '+ -',\n",
      " '+ Takt',\n",
      " '  .',\n",
      " '  Die',\n",
      " '  Linien',\n",
      " '  S41',\n",
      " '- u.',\n",
      " '+ u',\n",
      " '+ .',\n",
      " '  S42',\n",
      " '  fahren',\n",
      " '  nur',\n",
      " '  im',\n",
      " '- 10-Minuten-Takt',\n",
      " '+ 10',\n",
      " '+ -',\n",
      " '+ Minuten',\n",
      " '+ -',\n",
      " '+ Takt',\n",
      " '  ,',\n",
      " '  die',\n",
      " '  Linie',\n",
      " '  S46',\n",
      " '  fährt',\n",
      " '  nur',\n",
      " '  Königs',\n",
      " '  Wusterhausen',\n",
      " '+ <>',\n",
      " '- <',\n",
      " '- >',\n",
      " '  Tempelhof',\n",
      " '  .']\n",
      "\n",
      "\n",
      "spaCy: ['#', 'S3', ',', '#', 'S5', ',', '#', 'S7', ',', '#', 'S9', ':', 'Nach', 'einer', 'ärztliche', 'Versorgung', 'eines', 'Fahrgastes', 'im', 'Zug', 'in', 'Bellevue', 'kommt', 'es', 'noch', 'zu', 'Verspätungen', 'und', 'vereinzelten', 'Ausfällen', '.']\n",
      "stanfordnlp: ['#S3', ',', '#', 'S5', ',', '#', 'S7', ',', '#', 'S9', ':', 'Nach', 'einer', 'ärztliche', 'Versorgung', 'eines', 'Fahrgastes', 'im', 'Zug', 'in', 'Bellevue', 'kommt', 'es', 'noch', 'zu', 'Verspätungen', 'und', 'vereinzelten', 'Ausfällen', '.']\n",
      "somajo: ['#S3', ',', '#S5', ',', '#S7', ',', '#S9', ':', 'Nach', 'einer', 'ärztliche', 'Versorgung', 'eines', 'Fahrgastes', 'im', 'Zug', 'in', 'Bellevue', 'kommt', 'es', 'noch', 'zu', 'Verspätungen', 'und', 'vereinzelten', 'Ausfällen', '.']\n",
      "\n",
      "Differences:\n",
      "['- #',\n",
      " '- S3',\n",
      " '+ #S3',\n",
      " '? +\\n',\n",
      " '  ,',\n",
      " '  #',\n",
      " '  S5',\n",
      " '  ,',\n",
      " '  #',\n",
      " '  S7',\n",
      " '  ,',\n",
      " '  #',\n",
      " '  S9',\n",
      " '  :',\n",
      " '  Nach',\n",
      " '  einer',\n",
      " '  ärztliche',\n",
      " '  Versorgung',\n",
      " '  eines',\n",
      " '  Fahrgastes',\n",
      " '  im',\n",
      " '  Zug',\n",
      " '  in',\n",
      " '  Bellevue',\n",
      " '  kommt',\n",
      " '  es',\n",
      " '  noch',\n",
      " '  zu',\n",
      " '  Verspätungen',\n",
      " '  und',\n",
      " '  vereinzelten',\n",
      " '  Ausfällen',\n",
      " '  .']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spacy_doc, stanford_doc, somajo_doc in zip(spacy_docs, stanford_docs, somajo_docs):\n",
    "    spacy_tokens = get_spacy_doc_tokens(spacy_doc)\n",
    "    print(\"spaCy:\", spacy_tokens)\n",
    "    stanford_tokens = get_stanford_doc_tokens(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_tokens)\n",
    "    somajo_tokens = get_somajo_doc_tokens(somajo_doc)\n",
    "    print(\"somajo:\", somajo_tokens)\n",
    "    print(\"\\nDifferences:\")\n",
    "    print_list_differences(spacy_tokens, stanford_tokens)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitting comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_sentences(doc):\n",
    "    return [s.text for s in doc.sents]\n",
    "\n",
    "def get_stanford_doc_sentences(doc):\n",
    "    # introduces whitespaces\n",
    "    # see: https://github.com/stanfordnlp/stanfordnlp/blob/dev/stanfordnlp/models/common/doc.py\n",
    "    # to get original sentence text\n",
    "    return [\" \".join([token.text for token in sentence.tokens]) for sentence in doc.sentences]\n",
    "\n",
    "def get_somajo_doc_sentences(doc):\n",
    "    # introduces whitespaces\n",
    "    return [\" \".join([token.text for token in sentence]) for sentence in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy: 7 \n",
      " ['#S1', 'Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend, erster Zug ab', '#', 'Frohnau', '21:58 Uhr und erster Zug ab', '#Hohen_Neuendorf', '22:03 Uhr.']\n",
      "stanfordnlp: 1 \n",
      " ['#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S- Bahnen wieder durchgehend , erster Zug ab # Frohnau 21:58 Uhr und erster Zug ab # Hohen_Neuendorf 22:03 Uhr .']\n",
      "somajo: 1 \n",
      " ['#S1 Nach der Weichenstörung in Hohen Neuendorf verkehren die S-Bahnen wieder durchgehend , erster Zug ab #Frohnau 21:58 Uhr und erster Zug ab #Hohen_Neuendorf 22:03 Uhr .']\n",
      "\n",
      "\n",
      "spaCy: 5 \n",
      " ['Unfall\\nAbschnitt: Marzahn (Berlin)\\n', 'Gültig ab', ':', '09.02.2016', '20:06\\ngesperrt, Unfall\\n']\n",
      "stanfordnlp: 1 \n",
      " ['Unfall Abschnitt : Marzahn ( Berlin ) Gültig ab : 09.02.2016 20:06 gesperrt , Unfall']\n",
      "somajo: 1 \n",
      " ['Unfall Abschnitt : Marzahn ( Berlin ) Gültig ab : 09. 02. 2016 20:06 gesperrt , Unfall']\n",
      "\n",
      "\n",
      "spaCy: 6 \n",
      " ['■', '#', 'A1 #Bremen', 'Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn', '9 km #Stau.  ', 'Dort ist wegen #Bauarbeiten nur eine Spur frei.\\n']\n",
      "stanfordnlp: 2 \n",
      " ['■ # A1 # Bremen Richtung # Hamburg zwischen Horster Dreieck und # Stillhorn 9 km # Stau .', 'Dort ist wegen # Bauarbeiten nur eine Spur frei .']\n",
      "somajo: 2 \n",
      " ['■ #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau .', 'Dort ist wegen #Bauarbeiten nur eine Spur frei .']\n",
      "\n",
      "\n",
      "spaCy: 7 \n",
      " ['Wegen einer techn.', 'Störung an der Strecke besteht für die Linien S41, S42 u. S46 zw.', 'Halensee <>', 'Westkreuz <>', 'Messe Nord <>', 'Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt.', 'Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt, die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof.']\n",
      "stanfordnlp: 5 \n",
      " ['Wegen einer techn .', 'Störung an der Strecke besteht für die Linien S41 , S42 u .', 'S46 zw . Halensee <> Westkreuz <> Messe Nord <> Westend S - Bahn - Pendelverkehr im 20 - Minuten - Takt .', 'Die Linien S41 u .', 'S42 fahren nur im 10 - Minuten - Takt , die Linie S46 fährt nur Königs Wusterhausen <> Tempelhof .']\n",
      "somajo: 2 \n",
      " ['Wegen einer techn. Störung an der Strecke besteht für die Linien S41 , S42 u. S46 zw. Halensee < > Westkreuz < > Messe Nord < > Westend S-Bahn-Pendelverkehr im 20-Minuten-Takt .', 'Die Linien S41 u. S42 fahren nur im 10-Minuten-Takt , die Linie S46 fährt nur Königs Wusterhausen < > Tempelhof .']\n",
      "\n",
      "\n",
      "spaCy: 2 \n",
      " ['#S3, #S5, #S7,', '#S9: Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen.']\n",
      "stanfordnlp: 1 \n",
      " ['#S3 , # S5 , # S7 , # S9 : Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen .']\n",
      "somajo: 1 \n",
      " ['#S3 , #S5 , #S7 , #S9 : Nach einer ärztliche Versorgung eines Fahrgastes im Zug in Bellevue kommt es noch zu Verspätungen und vereinzelten Ausfällen .']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spacy_doc, stanford_doc, somajo_doc in zip(spacy_docs, stanford_docs, somajo_docs):\n",
    "    spacy_sentences = get_spacy_doc_sentences(spacy_doc)\n",
    "    print(\"spaCy:\", len(spacy_sentences), \"\\n\", spacy_sentences)\n",
    "    stanford_sentences = get_stanford_doc_sentences(stanford_doc)\n",
    "    print(\"stanfordnlp:\", len(stanford_sentences), \"\\n\", stanford_sentences)\n",
    "    somajo_sentences = get_somajo_doc_sentences(somajo_doc)\n",
    "    print(\"somajo:\", len(somajo_sentences), \"\\n\", somajo_sentences)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoS comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_pos(doc):\n",
    "    # fine-grained would be token.tag\n",
    "    return [token.tag_ for token in doc]\n",
    "\n",
    "def get_stanford_doc_pos(doc):\n",
    "    return [word.pos for sentence in doc.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_pos = get_spacy_doc_pos(spacy_doc)\n",
    "    print(spacy_doc.text)\n",
    "    print(\"spaCy:\", spacy_pos)\n",
    "    stanford_pos = get_stanford_doc_pos(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_pos)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc_dep(doc):\n",
    "    return [token.dep_ for token in doc]\n",
    "\n",
    "def get_stanford_doc_dep(doc):\n",
    "    return [word.dependency_relation for sentence in doc.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spacy_doc, stanford_doc in zip(spacy_docs, stanford_docs):\n",
    "    spacy_dep = get_spacy_doc_dep(spacy_doc)\n",
    "    print(spacy_doc.text)\n",
    "    print(\"spaCy:\", spacy_dep)\n",
    "    stanford_dep = get_stanford_doc_dep(stanford_doc)\n",
    "    print(\"stanfordnlp:\", stanford_dep)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
