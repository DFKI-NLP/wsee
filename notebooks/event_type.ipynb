{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the data to work with Snorkel: Part 1 - Event Type\n",
    "\n",
    "Essentially we will have to create two labeling models.\n",
    "One assigns labels to event types and the other assigns labels to argument roles in event mentions.\n",
    "\n",
    "In any case we need to create a row for each event (trigger) to do event type labeling.\n",
    "\n",
    "For this we need 1 additional column:\n",
    "- trigger_id\n",
    "\n",
    "One numpy array containing the:\n",
    "- event_type\n",
    "\n",
    "We will probably focus on keyword lists and some heuristics to create our labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from wsee.utils import utils\n",
    "from wsee.data.pipeline import load_data, build_event_trigger_examples\n",
    "\n",
    "DATA_DIR = '/Users/phuc/data/snorkel-daystreamv5'  # replace path to corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_data(DATA_DIR)\n",
    "sd_train = loaded_data['train']\n",
    "sd_dev = loaded_data['dev']\n",
    "sd_test = loaded_data['test']\n",
    "\n",
    "daystream = loaded_data['daystream']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example .jsonl file\n",
    "```json\n",
    "{\n",
    "  \"id\": \"754201930264633344\",\n",
    "  \"text\": \"â–  #A1 #Bremen Richtung #Hamburg zwischen Horster Dreieck und #Stillhorn 9 km #Stau.  Dort ist wegen #Bauarbeiten nur eine Spur frei.\\n\",\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"id\": \"c/82bf4c32-861d-4e09-b8d1-bf7adc488f2b\",\n",
    "      \"text\": \"#A1\",\n",
    "      \"entity_type\": \"location_street\",\n",
    "      \"start\": 1,\n",
    "      \"end\": 2,\n",
    "      \"char_start\": 2,\n",
    "      \"char_end\": 5\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"event_triggers\": [\n",
    "    {\n",
    "      \"id\": \"c/3958da47-7b47-414f-8210-5b2c487de9df\",\n",
    "      \"event_type_probs\": [ 0.0, ..., 1.0, 0.0 ]\n",
    "    }\n",
    "  ],\n",
    "  \"event_roles\": [\n",
    "    {\n",
    "      \"trigger\": \"c/3958da47-7b47-414f-8210-5b2c487de9df\",\n",
    "      \"argument\": \"c/82bf4c32-861d-4e09-b8d1-bf7adc488f2b\",\n",
    "      \"event_argument_probs\": [ 1.0, 0.0, ..., 0.0 ]\n",
    "    },\n",
    "    \n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create one row for every event trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_rows, event_type_rows_y = build_event_trigger_examples(sd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_rows_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test, Y_test = build_event_trigger_examples(sd_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee import SD4M_RELATION_TYPES\n",
    "print(SD4M_RELATION_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.preprocessors.preprocessors import *\n",
    "from wsee.data import explore, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply all our preprocessors on our data and see if we can find something interesting for our labeling functions.\n",
    "Let's first sample the SD4M training data, which is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_triggers = explore.add_labels(event_type_rows, event_type_rows_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_triggers = explore.apply_preprocessors(labeled_sd4m_triggers, [get_trigger, get_trigger_text, get_left_tokens, get_right_tokens, get_entity_type_freqs, get_mixed_ner])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the trigger text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_triggers[labeled_sd4m_triggers['label'] != 7].sample(10)[['text','trigger_text','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can collect the trigger words per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "filtered_sd4m_triggers = labeled_sd4m_triggers[labeled_sd4m_triggers['label'] != 7]\n",
    "class_keywords = {}\n",
    "print(f\"Number of triggers: {len(labeled_sd4m_triggers)}\\n\")\n",
    "for idx, class_name in enumerate(SD4M_RELATION_TYPES):\n",
    "    class_sd4m_triggers = labeled_sd4m_triggers[labeled_sd4m_triggers['label'] == idx]\n",
    "    print(f\"{class_name}: {len(class_sd4m_triggers)} instances\")\n",
    "    class_keywords[class_name] = class_sd4m_triggers['trigger_text']\n",
    "    print(class_sd4m_triggers['trigger_text'].value_counts()[:n].index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the labeling functions on the SD4M training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.labeling.event_trigger_lfs import lf_accident_cat, lf_canceledstop_cat, lf_canceledroute_cat, lf_delay_cat, \\\n",
    "    lf_obstruction_cat, lf_railreplacementservice_cat, lf_trafficjam_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_accident_cat,\n",
    "    lf_canceledroute_cat,\n",
    "    lf_canceledstop_cat,\n",
    "    lf_delay_cat,\n",
    "    lf_obstruction_cat,\n",
    "    lf_railreplacementservice_cat,\n",
    "    lf_trafficjam_cat\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_valid = applier.apply(event_type_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "Y_valid = event_type_rows_y\n",
    "LFAnalysis(L_valid, lfs).lf_summary(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L_test, lfs).lf_summary(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Labeling model and label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=7, verbose=True)\n",
    "label_model.fit(L_train=L_valid, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L=L_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=event_type_rows, y=probs_train, L=L_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
