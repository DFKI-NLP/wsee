{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the data to work with Snorkel: Part 1 - Event Type\n",
    "\n",
    "Essentially we will have to create two labeling models.\n",
    "One assigns labels to event types and the other assigns labels to argument roles in event mentions.\n",
    "\n",
    "In any case we need to create a row for each event (trigger) to do event type labeling.\n",
    "\n",
    "For this we need 1 additional column:\n",
    "- trigger_id\n",
    "\n",
    "One numpy array containing the:\n",
    "- event_type\n",
    "\n",
    "We will probably focus on keyword lists and some heuristics to create our labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wsee.utils import utils\n",
    "from wsee.data import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='once')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "DATA_DIR = '/Users/phuc/data/daystream_corpus'  # replace path to corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SD4M Event Types\n",
    "\n",
    "| Number | Code                   | Description                                                                             |\n",
    "|--------|------------------------|-----------------------------------------------------------------------------------------|\n",
    "| -1     | ABSTAIN                | No vote, for Labeling Functions                                                         |\n",
    "| 0      | Accident               | Collision of a vehicle with another vehicle, person, or obstruction                     |\n",
    "| 1      | CanceledRoute          | Cancellation of public transport routes                                                 |\n",
    "| 2      | CanceledStop           | Cancellation of public transport stops                                                  |\n",
    "| 3      | Delay                  | Delay resulting from remaining traffic disturbances                                     |\n",
    "| 4      | Obstruction            | Temporary installation to control traffic                                               |\n",
    "| 5      | RailReplacementService | Replacement of a passenger train by buses or other substitute public transport services |\n",
    "| 6      | TrafficJam             | Line of stationary or very slow-moving traffic                                          |\n",
    "| 7      | O                      | No SD4M event.                                                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pipeline.load_data(DATA_DIR)\n",
    "sd_train = loaded_data['train']\n",
    "sd_dev = loaded_data['dev']\n",
    "sd_test = loaded_data['test']\n",
    "\n",
    "daystream = loaded_data['daystream']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create one row for every event trigger\n",
    "\n",
    "We will use the (labeled) SD4M training set as our development data to create our labeling functions.\n",
    "In this notebook we will run our labeling functions and our LabelModel on that data.\n",
    "In the real pipeline we will instead label the Daystream data that does not have event type and event argument role labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_train, Y_sd_train = pipeline.build_event_trigger_examples(sd_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the (labeled) SD4m development set as our \"test set\" to measure the performance of our LabelModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_dev, Y_sd_dev = pipeline.build_event_trigger_examples(sd_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee import SD4M_RELATION_TYPES\n",
    "print(SD4M_RELATION_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.preprocessors.preprocessors import *\n",
    "from wsee.data import explore, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply all our preprocessors on our data and see if we can find something interesting for our labeling functions.\n",
    "Let's first sample the SD4M training data, which is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_triggers = explore.add_labels(df_sd_train, Y_sd_train)\n",
    "labeled_sd4m_triggers = explore.apply_preprocessors(labeled_sd4m_triggers, [pre_trigger_left_tokens, pre_mixed_ner, pre_trigger_right_tokens])\n",
    "labeled_sd4m_triggers = explore.add_event_types(labeled_sd4m_triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sd4m_triggers = labeled_sd4m_triggers[labeled_sd4m_triggers['label'] != 7]\n",
    "print(f\"Number of events: {len(labeled_sd4m_triggers)}\\n\")\n",
    "for idx, class_name in enumerate(SD4M_RELATION_TYPES):\n",
    "    class_sd4m_triggers = labeled_sd4m_triggers[labeled_sd4m_triggers['label'] == idx]\n",
    "    print(f\"{class_name}: {len(class_sd4m_triggers)} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the labeling functions on the SD4M training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.labeling import event_trigger_lfs as trigger_lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    trigger_lfs.lf_accident_context,\n",
    "    trigger_lfs.lf_accident_context_street,\n",
    "    trigger_lfs.lf_accident_context_no_cause_check,\n",
    "    trigger_lfs.lf_canceledroute_cat,\n",
    "    trigger_lfs.lf_canceledroute_replicated,\n",
    "    trigger_lfs.lf_canceledstop_cat,\n",
    "    trigger_lfs.lf_canceledstop_replicated,\n",
    "    trigger_lfs.lf_delay_cat,\n",
    "    trigger_lfs.lf_delay_priorities,\n",
    "    trigger_lfs.lf_delay_duration,\n",
    "    trigger_lfs.lf_obstruction_cat,\n",
    "    trigger_lfs.lf_obstruction_street,\n",
    "    trigger_lfs.lf_obstruction_priorities,\n",
    "    trigger_lfs.lf_railreplacementservice_cat,\n",
    "    trigger_lfs.lf_railreplacementservice_replicated,\n",
    "    trigger_lfs.lf_trafficjam_cat,\n",
    "    trigger_lfs.lf_trafficjam_street,\n",
    "    trigger_lfs.lf_trafficjam_order,\n",
    "    trigger_lfs.lf_negative,\n",
    "    trigger_lfs.lf_cause_negative,\n",
    "    trigger_lfs.lf_obstruction_negative\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sd_train = applier.apply(df_sd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L_sd_train, lfs).lf_summary(Y_sd_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Error Analysis \n",
    "Now we can look at the LabelMatrix for errors. We can use the DataFrame from the exploration section, which includes the information from the preprocessors.\n",
    "We can then specifically look for the instances that were labeled incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.labeling import error_analysis\n",
    "relevant_cols = ['text','trigger', 'event_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_triggers.iloc[L_sd_train[:, 3] == 1].sample()[['text', 'trigger', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis.sample_fp(labeled_df=labeled_sd4m_triggers, lf_outputs=L_sd_train, lf_index=3, label_of_interest=1, sample_size=1)[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis.sample_abstained_instances(labeled_df=labeled_sd4m_triggers, lf_outputs=L_sd_train, lf_index=10, label_of_interest=4, sample_size=1)[relevant_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Labeling model and label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "from snorkel.labeling import filter_unlabeled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daystream, Y_daystream = pipeline.build_event_trigger_examples(daystream)\n",
    "L_daystream = applier.apply(df_daystream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L_daystream, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daystream_model = LabelModel(cardinality=8, verbose=True)\n",
    "daystream_model.fit(L_train=L_daystream,n_epochs=5000, log_freq=500, seed=12345, Y_dev=Y_sd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daystream_model_acc = daystream_model.score(L=L_sd_train, Y=Y_sd_train, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {daystream_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daystream_probs = daystream_model.predict_proba(L=L_daystream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the proposed workflow one would filter out all the datapoints that were not labeled by any of the labeling functions.\n",
    "There will not be such a case here because we use a negative labeling functions that outputs the negative trigger label, when all the other labeling functions abstain.\n",
    "If it was not the case, we would instead multiply the probabilities of abstains with zero so that they look like padding instances, when fed into the end model.\n",
    "We propose this workaround since examples that are filtered out here are treated as negative examples per default in the end model.\n",
    "We also cannot afford to filter out the whole document if just one trigger/role example was not labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_daystream = pipeline.merge_event_trigger_examples(df_daystream, daystream_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_daystream.reset_index(level=0).to_json(DATA_DIR + \"/save_daystreamv6_triggers.jsonl\", orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check Daystream Labeling\n",
    "\n",
    "To look at the daystream labeling it would be best to remove the abstains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_daystream_filtered, probs_daystream_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_daystream, y=daystream_probs, L=L_daystream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daystream_filtered['trigger_probs'] = list(probs_daystream_filtered)\n",
    "df_daystream_filtered['most_probable_class'] = [SD4M_RELATION_TYPES[label_idx] for label_idx in probs_daystream_filtered.argmax(axis=1)]\n",
    "df_daystream_filtered['max_class_prob'] = [\"{:.2f}\".format(class_prob) for class_prob in probs_daystream_filtered.max(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trigger_class in SD4M_RELATION_TYPES:\n",
    "    print(f\"{trigger_class}: {len(df_daystream_filtered[df_daystream_filtered['most_probable_class'] == trigger_class])} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to display all the rows of the dataframe:\n",
    "```python\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df_daystream_filtered[df_daystream_filtered['most_probable_class'] == 'O'][['text', 'trigger', 'most_probable_class', 'max_class_prob', 'trigger_probs']])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daystream_filtered[df_daystream_filtered['most_probable_class'] == 'CanceledRoute'].sample(1)[['text', 'trigger', 'most_probable_class', 'max_class_prob', 'trigger_probs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
