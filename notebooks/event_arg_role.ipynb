{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the data to work with Snorkel: Part 2 - Event Role\n",
    "\n",
    "Here we will do most of the work creating a labeling model that assigns labels to argument roles in event mentions.\n",
    "We need to create a row for each pair of trigger and entity mention.\n",
    "\n",
    "For this we need to create 2 additional columns:\n",
    "- trigger_id\n",
    "- argument_id\n",
    "\n",
    "Everything else we can pull from the other columns using Snorkel preprocessor functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from wsee.utils import utils\n",
    "from wsee.data import pipeline\n",
    "\n",
    "DATA_DIR = '/Users/phuc/data/snorkel-daystreamv5'  # replace path to corpus\n",
    "use_defaults = True\n",
    "suffix = '_with_events_and_defaults.jsonl' if use_defaults else '_with_events.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SD4M Relation/ Event Arguments\n",
    "\n",
    "| Number | Code       | Description                                                                 |\n",
    "|--------|------------|-----------------------------------------------------------------------------|\n",
    "| -1     | ABSTAIN    | No vote, for Labeling Functions                                             |\n",
    "| 0      | location   | Required argument for all events denoting the location.                     |\n",
    "| 1      | delay      | Optional argument denoting the delay associated with the event.             |\n",
    "| 2      | direction  | Optional argument denoting the direction associated with the event.         |\n",
    "| 3      | start_loc  | Optional argument denoting the starting location associated with the event. |\n",
    "| 4      | end_loc    | Optional argument denoting the ending location associated with the event.   |\n",
    "| 5      | start_date | Optional argument denoting the start date associated with the event.        |\n",
    "| 6      | end_date   | Optional argument denoting the end date associated with the event.          |\n",
    "| 7      | cause      | Optional argument (trigger) denoting the cause associated with the event.   |\n",
    "| 8      | jam_length | Optional argument denoting the jam length of a traffic jam event.           |\n",
    "| 9      | route      | Optional argument denoting the route affected by a canceled stop event.     |\n",
    "| 10     | no_arg     | No argument relation with the specified trigger.                            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pipeline.load_data(DATA_DIR)\n",
    "sd_train = loaded_data['train']\n",
    "sd_dev = loaded_data['dev']\n",
    "sd_test = loaded_data['test']\n",
    "\n",
    "daystream = loaded_data['daystream']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create one row for each trigger-entity pair (event role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE:\n",
    "    df_dev, Y_dev = pipeline.build_event_role_examples(sd_train.sample(n=50, random_state=42))\n",
    "else:\n",
    "    df_dev, Y_dev = pipeline.build_event_role_examples(sd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE:\n",
    "    df_test, Y_test = pipeline.build_event_role_examples(sd_dev.sample(n=20, random_state=42))\n",
    "else:\n",
    "    df_test, Y_test = pipeline.build_event_role_examples(sd_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee import ROLE_LABELS\n",
    "print(ROLE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.preprocessors.preprocessors import *\n",
    "from wsee.data import explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply all our preprocessors on our data and see if we can find something interesting for our labeling functions. Let's first sample the SD4M training data, which is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_roles = explore.add_labels(df_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_sd4m_roles = explore.apply_preprocessors(labeled_sd4m_roles, [get_trigger, get_trigger_left_tokens, get_trigger_text, get_trigger_right_tokens, get_argument, get_argument_left_tokens, get_argument_text, get_argument_right_tokens, get_between_distance, get_entity_type_freqs, get_mixed_ner])\n",
    "labeled_sd4m_roles = explore.apply_preprocessors(labeled_sd4m_roles, [get_trigger, get_trigger_text, get_argument, get_argument_text, get_between_tokens, get_between_distance, get_entity_type_freqs, get_mixed_ner, get_somajo_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_roles = explore.add_event_types(labeled_sd4m_roles)\n",
    "labeled_sd4m_roles = explore.add_event_arg_roles(labeled_sd4m_roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the trigger and argument text, and the entity types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore.sample_data(labeled_sd4m_roles[labeled_sd4m_roles['label']==0], columns=['text','trigger_left_tokens', 'trigger_text','trigger_right_tokens','argument_left_tokens', 'argument_text', 'argument_right_tokens', 'mixed_ner', 'label', 'event_types', 'event_arg_roles'])\n",
    "explore.sample_data(labeled_sd4m_roles[labeled_sd4m_roles['label']==5], columns=['text', 'tokens', 'trigger', 'argument', 'between_distance', 'mixed_ner', 'label', 'event_types', 'event_arg_roles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "event_arg_roles = list(labeled_sd4m_roles['event_arg_roles'])\n",
    "concatenated_roles = set(itertools.chain.from_iterable(event_arg_roles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_pairs = []\n",
    "delay_pairs = []\n",
    "direction_pairs = []\n",
    "start_loc_pairs = []\n",
    "end_loc_pairs = []\n",
    "start_date_pairs = []\n",
    "end_date_pairs = []\n",
    "cause_pairs = []\n",
    "jam_length_pairs = []\n",
    "route_pairs = []\n",
    "\n",
    "for pair in concatenated_roles: \n",
    "    if pair[-1] == 0:\n",
    "        location_pairs.append(pair)\n",
    "    elif pair[-1] == 1:\n",
    "        delay_pairs.append(pair)\n",
    "    elif pair[-1] == 2:\n",
    "        direction_pairs.append(pair)\n",
    "    elif pair[-1] == 3:\n",
    "        start_loc_pairs.append(pair)\n",
    "    elif pair[-1] == 4:\n",
    "        end_loc_pairs.append(pair)\n",
    "    elif pair[-1] == 5:\n",
    "        start_date_pairs.append(pair)\n",
    "    elif pair[-1] == 6:\n",
    "        end_date_pairs.append(pair)\n",
    "    elif pair[-1] == 7:\n",
    "        cause_pairs.append(pair)\n",
    "    elif pair[-1] == 8:\n",
    "        jam_length_pairs.append(pair)\n",
    "    elif pair[-1] == 9:\n",
    "        route_pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([pair for pair in end_loc_pairs if pair[1] == 5])\n",
    "print(len(event_arg_roles), len(concatenated_roles), len(location_pairs))\n",
    "[pair for pair in route_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can collect the most frequent trigger-argument pairs per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "filtered_sd4m_roles = labeled_sd4m_roles[labeled_sd4m_roles['label'] != 10]\n",
    "class_pairs = {}\n",
    "print(f\"Number of event-roles: {len(labeled_sd4m_roles)}\\n\")\n",
    "for idx, class_name in enumerate(ROLE_LABELS):\n",
    "    class_sd4m_roles = labeled_sd4m_roles[labeled_sd4m_roles['label'] == idx]\n",
    "    print(f\"{class_name}: {len(class_sd4m_roles)} instances\")\n",
    "    class_pairs[class_name] = (class_sd4m_roles['trigger_text'], class_sd4m_roles['argument_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only checking the argument text probably does not give us much, but it shall serve as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sd4m_roles[labeled_sd4m_roles['label'] == 5]['argument_text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the labeling functions on the SD4M training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.labeling.event_argument_role_lfs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_location_same_sentence_is_event,\n",
    "    lf_location_same_sentence_nearest_is_event,\n",
    "    lf_delay_event_sentence,\n",
    "    lf_direction_type,\n",
    "    lf_direction_nearest,\n",
    "    lf_loc_stop_direction_type,\n",
    "    lf_loc_stop_direction_nearest,\n",
    "    lf_loc_loc_city_direction_type,\n",
    "    lf_loc_loc_city_direction_nearest,\n",
    "    lf_start_location_type,\n",
    "    lf_end_location_type,\n",
    "    lf_start_date_type,\n",
    "    lf_end_date_type,\n",
    "    lf_cause_type,\n",
    "    lf_cause_gaz_file,\n",
    "    lf_distance_type,\n",
    "    lf_route_type,\n",
    "    lf_not_an_event,\n",
    "    lf_somajo_separate_sentence,\n",
    "    lf_overlapping,\n",
    "    lf_not_nearest_event,\n",
    "    lf_not_nearest_same_sentence_event,\n",
    "    lf_too_far_20,\n",
    "    lf_too_far_30,\n",
    "    lf_too_far_40,\n",
    "    lf_event_patterns,\n",
    "    lf_event_patterns_general_location,\n",
    "    lf_event_patterns_general_location_type,\n",
    "    lf_event_patterns_general_delay_type,\n",
    "    lf_event_patterns_general_startloc_type,\n",
    "    lf_event_patterns_general_endloc_type,\n",
    "    lf_event_patterns_general_startdate_type,\n",
    "    lf_event_patterns_general_enddate_type,\n",
    "    lf_event_patterns_general_cause_type,\n",
    "    lf_event_patterns_general_jamlength_type\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_dev = applier.apply(df_dev)\n",
    "L_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L_dev, lfs).lf_summary(Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsee.labeling import error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis.sample_fp(labeled_df=labeled_sd4m_roles, lf_outputs=L_dev, lf_index=33, label_of_interest=9)[['between_tokens', 'trigger', 'argument', 'somajo_doc', 'label', 'event_types', 'event_arg_roles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis.trigger_text_counts_fp(labeled_df=labeled_sd4m_roles, lf_outputs=L_dev, lf_index=0, label_of_interest=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis.sample_abstained_instances(labeled_df=labeled_sd4m_roles, lf_outputs=L_dev, lf_index=30, label_of_interest=7)[['between_tokens', 'trigger', 'argument', 'somajo_doc', 'label', 'event_types', 'event_arg_roles']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Labeling model and label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=11, verbose=True)\n",
    "label_model.fit(L_train=L_dev, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L=L_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_dev, y=probs_train, L=L_dev\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_sd_train = pipeline.merge_event_role_examples(df_dev, probs_train)\n",
    "labeled_sd_train = pipeline.merge_event_role_examples(df_train_filtered, probs_train_filtered)\n",
    "import pickle\n",
    "pickle.dump(labeled_sd_train, open( \"/Users/phuc/develop/python/wsee/data/save_sd_roles.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Label the Daystream data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, Y_train = pipeline.build_event_role_examples(daystream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = applier.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L_train, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daystream_model = LabelModel(cardinality=11, verbose=True)\n",
    "daystream_model.fit(L_train=L_dev, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daystream_model_acc = daystream_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {daystream_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daystream_probs = daystream_model.predict_proba(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=daystream_probs, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_daystream = pipeline.merge_event_role_examples(df_train_filtered, probs_train_filtered)\n",
    "import pickle\n",
    "pickle.dump(labeled_sd_train, open( \"/Users/phuc/develop/python/wsee/data/save_daystream_roles.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (master)",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
